{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "import pandas as pd\n",
    "\n",
    "cred = credentials.Certificate(\n",
    "    \"./netflix-comment-system-firebase-adminsdk-hq5cn-ad06fee744.json\")\n",
    "firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "doc_ref = db.collection('Comments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a data structure to access different collections easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drama_db = {doc.id: doc_ref.document(doc.id) for doc in doc_ref.get()}\n",
    "drama_db_list = list(drama_db.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the local data into the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "drama_pic = pd.read_csv('../scrape_for_comp/drama_pic.csv')\n",
    "douban_df = pd.read_csv('./douban_score_info.csv')\n",
    "post_df = pd.read_csv('../scrape_for_comp/Posts_from_fb.csv')\n",
    "comment_df = pd.read_csv('../scrape_for_comp/Comments_from_fb.csv')\n",
    "imdb = pd.read_csv('./netflix_scores.csv')\n",
    "rottentomatoes = pd.read_csv('../scrape_for_comp/rottentomatoes_scores.csv')\n",
    "\n",
    "with open('../scrape_for_comp/drama_post_dt.json') as fh:\n",
    "    drama_post_dt = json.load(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import drama image urls into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in drama_pic.iterrows():\n",
    "    if row['name'] in drama_db.set({'img': row.img_url})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import drama introduction and scores from douban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in douban_df.iterrows():\n",
    "    if row['name'] in drama_db_list:\n",
    "        drama_db[row['name']].update({'info': row['info']})\n",
    "        drama_db[row['name']].document().set({'source': '豆瓣', 'score': row.score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with the comments\n",
    "1. extract the comments under the posts related to the drama\n",
    "2. separate the comments by sentiment scores\n",
    "3. load them into the database respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in drama_post_dt.items():\n",
    "    if len(v) == 0:\n",
    "        continue\n",
    "    print(k, 'comment loading')\n",
    "    comments = pd.DataFrame()\n",
    "    for pid in v:\n",
    "        comments = comments.append(comment_df[comment_df.post_id == int(pid)])\n",
    "    pos_comment = comments[comments.sentiment >= 5]\n",
    "    neg_comment = comments[comments.sentiment < 5]\n",
    "    for idx, row in pos_comment.iterrows():\n",
    "        if k in drama_db_list:\n",
    "            cm_dt = dict()\n",
    "            cm_dt['time'] = row.comment_time\n",
    "            cm_dt['text'] = row.comment_text\n",
    "            cm_dt['score'] = row.sentiment\n",
    "            drama_db[k].collection('pos_comment').document(str(row.comment_id)).set(cm_dt)\n",
    "\n",
    "    for idx, row in neg_comment.iterrows():\n",
    "        if k in drama_db_list:\n",
    "            cm_dt = dict()\n",
    "            cm_dt['time'] = row.comment_time\n",
    "            cm_dt['text'] = row.comment_text\n",
    "            cm_dt['score'] = row.sentiment\n",
    "            drama_db[k].collection('neg_comment').document(str(row.comment_id)).set(cm_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the scores from IMDb and rotten tomatoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in imdb.iterrows():\n",
    "    if row['名稱'] in drama_db_list:\n",
    "        drama_db[row['名稱'].replace('/', '-')].collection('scores').document().set({'score': row['評分'], 'source': row['來源']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in rottentomatoes.iterrows():\n",
    "    if row['name'] in drama_db_list:\n",
    "        score_dt = {'tomatometer': row['tomatometer'], 'audience': row['audience'], 'source': '爛番茄'}\n",
    "        drama_db[row['name'].replace('/', '-')].collection('scores').document().set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}